{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5d1811-5632-4bdf-9171-b48ef491db15",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de666aa-011a-4a26-a85b-00720aa67af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e918d-09bf-40a2-a7b9-8a86998058c7",
   "metadata": {},
   "source": [
    "# Keypoints Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca66ae2-3589-4e86-a607-fca61b9c7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54332816-aeea-42ec-a8f4-877d37c3e4c0",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ee6869-d0b5-4b8f-a8c9-ec492f98031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('C:\\\\Users\\\\mahat\\\\SignLanguageTranslation\\\\MP_DATA') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['hello', 'thanks', 'iloveyou'])\n",
    "# actions = np.array(['hello', 'father', 'me', 'mother', 'yes', 'no', 'help', 'please', 'what', 'cat', 'repeate', 'eat', 'milk', 'more', 'fine', 'thanks', 'you', 'how', 'so-so'])\n",
    "\n",
    "\n",
    "# Thirty videos worth of data for each image\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n",
    "# Folder start\n",
    "start_folder = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf25de1-d8b0-437d-850f-15bfdb6df42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2da28e-468f-4c79-85b5-e0faa2688b90",
   "metadata": {},
   "source": [
    "# Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06566f-aa1d-4d46-9a91-5de4da09550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "        # Looping through actions\n",
    "        for action in actions:\n",
    "            # Looping through sequence:\n",
    "            for sequence in range(no_sequences):\n",
    "                #Looping throught video length\n",
    "                for frame_num in range(sequence_length):\n",
    "                    \n",
    "                    # Read feed\n",
    "                    ret, frame = cap.read()\n",
    "                    # frame = cv2.flip(frame, 1) dont flip \n",
    "            \n",
    "                    # Make detections\n",
    "                    image, results = mediapipe_detection(frame, holistic)\n",
    "                    print(results)\n",
    "                    \n",
    "                    # Draw landmarks\n",
    "                    draw_landmarks(image, results)\n",
    "\n",
    "                    \n",
    "                    # Apply wait logic\n",
    "                    if frame_num == 0: \n",
    "                        cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA) #line width = 4\n",
    "                        cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "                        cv2.waitKey(500)\n",
    "                    else: \n",
    "                        cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                    #Keypoint extraction\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                    np.save(npy_path, keypoints) #This saves the keypoints array into the file named as frame_num.npy\n",
    "            \n",
    "                   \n",
    "\n",
    "                    # Break gracefully\n",
    "                    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                        break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2c854-8f27-4d17-8c92-b9f970676247",
   "metadata": {},
   "source": [
    "# One hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2464b2be-a000-49a7-8ff1-002ea1f1ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34bec4e-0d0a-457b-8bfd-aeeb9738cd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'iloveyou': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label: num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1b8c7bf-8522-41c1-ac0e-3f2d7e7e626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c2b2a74-b8b0-49b5-a9f4-6fbce7595f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cefafda4-8599-485b-87e2-a041879dea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5afa118c-b175-4cb9-94b3-5b840e77f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70be089f-7795-45b9-a90c-2ec3c0f97191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60cc69a4-9481-4283-a67a-73ee3b211b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af75ae1-a250-4ecb-b381-5a56925ca9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5b082a9-cbb3-402a-b530-ffdba9d05d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091d5f7-8957-4749-8814-67834cd3b731",
   "metadata": {},
   "source": [
    "# Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4c2ba74-5829-4370-9144-aa51196be02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "572562b4-4014-43a1-9a05-4c81bcce2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b690754-3177-4eed-9f58-36301f91a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2ce445a-70f9-4a9e-831a-30bd52a98a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fcc4954-96b6-4821-bb33-c58f9955e63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - categorical_accuracy: 0.9765 - loss: 0.3027 - val_categorical_accuracy: 1.0000 - val_loss: 0.2754\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - categorical_accuracy: 0.9511 - loss: 0.2850 - val_categorical_accuracy: 1.0000 - val_loss: 0.1844\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - categorical_accuracy: 0.9706 - loss: 0.2083 - val_categorical_accuracy: 1.0000 - val_loss: 0.1511\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.9608 - loss: 0.1436 - val_categorical_accuracy: 1.0000 - val_loss: 0.0614\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.9472 - loss: 0.1843 - val_categorical_accuracy: 1.0000 - val_loss: 0.0758\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - categorical_accuracy: 0.9628 - loss: 0.1256 - val_categorical_accuracy: 1.0000 - val_loss: 0.0472\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.9745 - loss: 0.0922 - val_categorical_accuracy: 1.0000 - val_loss: 0.1473\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.9687 - loss: 0.1025 - val_categorical_accuracy: 0.8000 - val_loss: 0.4706\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.5967 - loss: 1.4346 - val_categorical_accuracy: 0.6000 - val_loss: 1.6703\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.5812 - loss: 1.2528 - val_categorical_accuracy: 0.6000 - val_loss: 0.8149\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.4227 - loss: 0.8867 - val_categorical_accuracy: 0.8000 - val_loss: 0.6947\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.7007 - loss: 0.8009 - val_categorical_accuracy: 1.0000 - val_loss: 0.7101\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - categorical_accuracy: 0.8747 - loss: 0.7633 - val_categorical_accuracy: 0.8000 - val_loss: 0.6658\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.7965 - loss: 0.7236 - val_categorical_accuracy: 0.6000 - val_loss: 0.5889\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - categorical_accuracy: 0.6575 - loss: 0.6270 - val_categorical_accuracy: 0.6000 - val_loss: 0.5335\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.7007 - loss: 0.5656 - val_categorical_accuracy: 1.0000 - val_loss: 0.4805\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.8512 - loss: 0.4781 - val_categorical_accuracy: 0.8000 - val_loss: 0.3901\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - categorical_accuracy: 0.9060 - loss: 0.5549 - val_categorical_accuracy: 0.8000 - val_loss: 0.3703\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - categorical_accuracy: 0.9002 - loss: 0.4061 - val_categorical_accuracy: 1.0000 - val_loss: 0.4714\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.9648 - loss: 0.4893 - val_categorical_accuracy: 1.0000 - val_loss: 0.4707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f218e65160>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data= (X_test, y_test) , epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f63472d0-9442-4e5e-b569-f648f92a76c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">442,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │         \u001b[38;5;34m442,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m98,816\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m99\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,654,091</span> (6.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,654,091\u001b[0m (6.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">551,363</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m551,363\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,102,728</span> (4.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,102,728\u001b[0m (4.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae28f223-5be1-4af5-9740-9ef322e027ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "491038f2-4ab2-4651-8a6c-6d6cb24180d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ecb4cb3-ff4b-4007-a825-ec86efac5da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebddc7-49d4-4f5c-a594-dd19883518c6",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dda2bce6-6dc9-45c9-98de-e62736709f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07b1a6db-d90d-4ba8-8458-b336199bc274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lstm_final_model.keras']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'lstm_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2fc2155-f406-420d-88c4-4b99cb5fe66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('lstm_final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2baf37a7-96d8-4b8a-9d66-95252a826d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_model.keras') # Dont run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d401e1-0bee-442f-80cb-77494b4f3a8b",
   "metadata": {},
   "source": [
    "# Evaluating Accuracy using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "595809c3-6fc3-4b50-91ed-01c229049f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e717888-b780-43da-b427-78ca87b2a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b80a5cb2-8860-4697-aae6-063db29d518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81c38a99-cdb2-45cd-a91c-3cc3adf3e812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 0],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[4, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [0, 2]]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb4db457-64a5-4a51-b19b-d51bd7e7f8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22543576-a73a-41a9-befd-43f49962d8ea",
   "metadata": {},
   "source": [
    "# Real- Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54bd1c05-e2ad-4568-9229-7d6f5cf6d2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frames...\n",
      "Input data:  [[[ 0.5036159   0.5118643  -0.93425447 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5037027   0.5118582  -0.84539825 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5037249   0.5116688  -0.8467848  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.49404234  0.50374454 -0.83344156 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4951076   0.50290924 -0.81817234 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49618864  0.50280714 -0.81700975 ...  0.          0.\n",
      "    0.        ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[0.8598579  0.01274831 0.1273938 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.50133264  0.5134061  -0.9088832  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.50130945  0.51376283 -0.9016892  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5012375   0.5137193  -0.8970129  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.488084    0.4817449  -0.71980023 ...  0.4432218   0.6174507\n",
      "   -0.0473641 ]\n",
      "  [ 0.48799333  0.48259696 -0.73992884 ...  0.41564783  0.63891345\n",
      "   -0.05264014]\n",
      "  [ 0.48552012  0.48272583 -0.76617146 ...  0.40071797  0.63800526\n",
      "   -0.05608843]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.25411898 0.34236792 0.4035131 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.4761835   0.46421096 -0.8014158  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.47613353  0.46119002 -0.7260646  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.47605166  0.45957837 -0.74325913 ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.46824694  0.46377018 -0.6306837  ...  0.45957083  0.5802317\n",
      "   -0.04022892]\n",
      "  [ 0.4684306   0.4635436  -0.6974847  ...  0.44749403  0.6047515\n",
      "   -0.05308675]\n",
      "  [ 0.468464    0.46348345 -0.7476284  ...  0.44074267  0.6180079\n",
      "   -0.05410924]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "[0.2565547 0.3370108 0.4064345]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.4816936   0.43270287 -0.71172583 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.48383984  0.42866036 -0.70802486 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4848958   0.42845365 -0.70140916 ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.48282725  0.4396238  -0.71020675 ...  0.38776276  0.770004\n",
      "   -0.07784773]\n",
      "  [ 0.4818171   0.4368726  -0.68149173 ...  0.38796347  0.7716857\n",
      "   -0.07117604]\n",
      "  [ 0.48107105  0.43612078 -0.68544936 ...  0.3686426   0.82533944\n",
      "   -0.06940988]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.2110275  0.45831224 0.3306602 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.48596844  0.44006035 -0.69674027 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.48599464  0.44104493 -0.6965631  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.48601714  0.44173616 -0.6960138  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.50429     0.469701   -0.6713065  ...  0.16646403  0.44640955\n",
      "   -0.02797598]\n",
      "  [ 0.50461876  0.46982506 -0.6661917  ...  0.16612075  0.4450599\n",
      "   -0.02517679]\n",
      "  [ 0.5046847   0.46981585 -0.69735515 ...  0.16499498  0.44399935\n",
      "   -0.0253317 ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "[0.4538342  0.11687206 0.42929378]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.5046929   0.4604188  -0.6983597  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.50434625  0.46058637 -0.699928   ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5009464   0.4593459  -0.70239747 ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.51317793  0.4706726  -0.68966204 ...  0.15880057  0.5101392\n",
      "   -0.0298278 ]\n",
      "  [ 0.51316464  0.47071484 -0.6897615  ...  0.1584149   0.5124998\n",
      "   -0.03179315]\n",
      "  [ 0.51318455  0.47088033 -0.67276037 ...  0.15426134  0.516474\n",
      "   -0.0275788 ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.43116617 0.12693493 0.44189894]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.5046514   0.46349838 -0.6926045  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.50421864  0.46270117 -0.6294997  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.50382763  0.46214595 -0.6172143  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.51176965  0.4755415  -0.6790235  ...  0.1494479   0.37695232\n",
      "   -0.01981231]\n",
      "  [ 0.511798    0.47554478 -0.6945266  ...  0.14962897  0.37671217\n",
      "   -0.02191026]\n",
      "  [ 0.5118202   0.47576624 -0.69393164 ...  0.14873832  0.38067698\n",
      "   -0.01901319]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[0.5652484  0.07351709 0.36123452]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.5066637   0.4665532  -0.69538707 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5059174   0.46480474 -0.6859519  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5053031   0.46403447 -0.6805181  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.5080694   0.47176707 -0.6353102  ...  0.13477755  0.5449025\n",
      "   -0.02563045]\n",
      "  [ 0.5083147   0.47171128 -0.62855685 ...  0.1353444   0.5458986\n",
      "   -0.02625889]\n",
      "  [ 0.5083292   0.47148576 -0.6180583  ...  0.1318748   0.54640687\n",
      "   -0.02650905]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[0.46796957 0.11006915 0.42196125]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.5075319   0.47273982 -0.7053373  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5071453   0.47156718 -0.73938537 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.505709    0.47140327 -0.7015706  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.5084783   0.48396894 -0.5792383  ...  0.14425221  0.5523686\n",
      "   -0.02243253]\n",
      "  [ 0.50847787  0.48453632 -0.58476055 ...  0.1441228   0.55459535\n",
      "   -0.02210119]\n",
      "  [ 0.5083399   0.48514226 -0.5862256  ...  0.14391495  0.5546931\n",
      "   -0.0223421 ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "[0.4985358  0.09686295 0.4046012 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.5034081   0.4797016  -0.6609262  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.50196314  0.4772773  -0.6578132  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5000628   0.4769165  -0.64826    ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.489897    0.4770723  -0.5980217  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.48983592  0.47721273 -0.596932   ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4898479   0.47754088 -0.60051763 ...  0.          0.\n",
      "    0.        ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.34843186 0.18248539 0.4690827 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.4944222   0.47827482 -0.69735634 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49386054  0.4780589  -0.7064716  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49122924  0.47790772 -0.7086333  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.4885941   0.49482936 -0.6127864  ...  0.48973748  0.6300117\n",
      "   -0.03982929]\n",
      "  [ 0.48904276  0.4953603  -0.6063966  ...  0.49228695  0.62821627\n",
      "   -0.039742  ]\n",
      "  [ 0.4890015   0.49517354 -0.59204686 ...  0.48324707  0.6434408\n",
      "   -0.04578221]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[0.26733077 0.29183915 0.44083005]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.49454588  0.45454285 -0.6623123  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49244538  0.4553247  -0.6533357  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.491525    0.45563546 -0.6658408  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.5006891   0.49120694 -0.5857142  ...  0.48961198  0.6306935\n",
      "   -0.04016025]\n",
      "  [ 0.50081193  0.49102196 -0.6284717  ...  0.48973593  0.6294596\n",
      "   -0.03771653]\n",
      "  [ 0.50071114  0.49174228 -0.65119827 ...  0.46658784  0.6650255\n",
      "   -0.04310935]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[0.26299864 0.31501448 0.42198688]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.48339233  0.449559   -0.7834927  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4831016   0.44924432 -0.7778624  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4830733   0.44930175 -0.78913623 ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.49195075  0.46636835 -0.63512075 ...  0.4375745   0.76844865\n",
      "   -0.04573202]\n",
      "  [ 0.4930117   0.46587577 -0.6557153  ...  0.4232656   0.7948527\n",
      "   -0.05063016]\n",
      "  [ 0.49497437  0.46587482 -0.6851093  ...  0.42326096  0.79247844\n",
      "   -0.05660197]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "[0.23823468 0.39040628 0.37135905]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.5121486   0.4532604  -0.69822156 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5113186   0.4514275  -0.6968409  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.510482    0.45049188 -0.692765   ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.50821763  0.46659634 -0.8100581  ...  0.4337366   0.7596141\n",
      "   -0.05394268]\n",
      "  [ 0.50849044  0.46339044 -0.7233981  ...  0.413324    0.8462671\n",
      "   -0.04226098]\n",
      "  [ 0.50910544  0.45636645 -0.6408622  ...  0.3987684   0.87152916\n",
      "   -0.04217388]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "[0.21406423 0.44959435 0.3363414 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.45975265  0.4748195  -0.70247257 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.46000618  0.47490025 -0.7364291  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.46013623  0.4750806  -0.7355164  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.487711    0.50145644 -0.61775184 ...  0.46911505  0.6323456\n",
      "   -0.03089462]\n",
      "  [ 0.48915043  0.5014365  -0.63700986 ...  0.4623522   0.6390283\n",
      "   -0.0349841 ]\n",
      "  [ 0.48991862  0.50152093 -0.63663757 ...  0.46537447  0.63714343\n",
      "   -0.03184173]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.26654786 0.2964933  0.43695882]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.49428     0.46726194 -0.6831755  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4942453   0.4642108  -0.6819172  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49422354  0.46021214 -0.6762807  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.51164514  0.45346603 -1.0087521  ...  0.43679434  0.7839261\n",
      "   -0.05248831]\n",
      "  [ 0.51154846  0.4535641  -0.71092135 ...  0.4042068   0.8933916\n",
      "   -0.0679103 ]\n",
      "  [ 0.5118654   0.45399454 -0.70940745 ...  0.          0.\n",
      "    0.        ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[0.21974574 0.44497603 0.33527827]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.51099354  0.43551198 -0.76542276 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.50983226  0.43539816 -0.76671517 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5066452   0.43541107 -0.7507424  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.50239706  0.4480355  -0.68776596 ...  0.143244    0.5818327\n",
      "   -0.01947205]\n",
      "  [ 0.50247943  0.44760805 -0.7121855  ...  0.15017307  0.57477593\n",
      "   -0.02741933]\n",
      "  [ 0.50252557  0.44762173 -0.83606416 ...  0.15028353  0.5826917\n",
      "   -0.02467244]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[0.33858502 0.1818875  0.4795274 ]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.49687886  0.44167224 -0.8274945  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49474654  0.4413212  -0.8275523  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49446502  0.44107786 -0.883577   ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.48715296  0.4597844  -0.7167274  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.48712912  0.46004343 -0.78724015 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.4870944   0.46029156 -0.7094508  ...  0.          0.\n",
      "    0.        ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[0.27630973 0.3006876  0.42300266]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.54138213  0.48642942 -0.7172488  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5427949   0.48553985 -0.7041148  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.5432368   0.4811782  -0.6747719  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.53327566  0.49425468 -0.8530966  ...  0.3583606   0.35496658\n",
      "   -0.04943433]\n",
      "  [ 0.53400004  0.49380594 -0.80017453 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.53493774  0.49474657 -0.79530895 ...  0.29756418  0.3571547\n",
      "   -0.0454359 ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[0.627716   0.05394016 0.31834388]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.47499108  0.47165734 -0.6828592  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.47451234  0.46887633 -0.67882526 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.47443715  0.46759892 -0.68092334 ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.46191224  0.49411887 -0.6040708  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.46189564  0.4928199  -0.60061294 ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.46172872  0.49286652 -0.6016517  ...  0.          0.\n",
      "    0.        ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[0.63103485 0.05967984 0.30928534]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.46628532  0.4746396  -0.631874   ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.46614188  0.4745832  -0.6373262  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.46534377  0.4743366  -0.6144444  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.4876489   0.4936487  -0.6876117  ...  0.38925967  0.7983214\n",
      "   -0.06377546]\n",
      "  [ 0.48925906  0.49048078 -0.6795012  ...  0.38741776  0.8087302\n",
      "   -0.06723062]\n",
      "  [ 0.4899631   0.4895053  -0.65084434 ...  0.3735837   0.8579442\n",
      "   -0.05196077]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[0.24243356 0.37638885 0.38117763]\n",
      "Collecting frames...\n",
      "Input data:  [[[ 0.4908699   0.45699206 -0.6616184  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49055415  0.45055002 -0.6701876  ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.49028617  0.44731167 -0.6743974  ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.49590582  0.45385155 -0.9849118  ...  0.42877048  0.74432474\n",
      "   -0.06729386]\n",
      "  [ 0.49622315  0.45241353 -0.95792216 ...  0.41251802  0.7728397\n",
      "   -0.06092608]\n",
      "  [ 0.49619898  0.45136848 -0.880301   ...  0.39244926  0.83885974\n",
      "   -0.05211578]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[0.23482299 0.40891257 0.35626447]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "collecting = False  # Flag to indicate collection state\n",
    "frames_collected = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process frame\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "\n",
    "        # Display instruction message\n",
    "        if collecting:\n",
    "            cv2.putText(image, \"Perform the sign\", (image.shape[1]//4, image.shape[0]//2), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "            frames_collected += 1\n",
    "            \n",
    "            if frames_collected == 30:\n",
    "                # Display message when collection is over\n",
    "                cv2.putText(image, \"Frame collection complete\", (image.shape[1]//4, image.shape[0]//2 + 40), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Perform prediction\n",
    "                input_data = np.expand_dims(sequence, axis=0).astype(np.float32)\n",
    "                # input_data = scaler.transform(input_data.reshape(-1, 1662)).reshape(input_data.shape)\n",
    "                print(\"Input data: \", input_data)\n",
    "                res = model.predict(input_data)[0]\n",
    "                \n",
    "                sequence = []  # Reset sequence\n",
    "                collecting = False  # Stop collection\n",
    "                frames_collected = 0  # Reset frame counter\n",
    "                print(res)\n",
    "                \n",
    "                # Confidence threshold check\n",
    "                if float(res[np.argmax(res)]) > threshold:\n",
    "                    if len(sentence) == 0 or actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                    \n",
    "                if len(sentence) > 5:\n",
    "                    sentence = sentence[-5:]  # Keep last 5 recognized words\n",
    "        \n",
    "        # Display recognized sentence\n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('Sign Language Recognition', image)\n",
    "        \n",
    "        # Key event handling\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('s') and not collecting:  # Start collection when 'S' is pressed\n",
    "            collecting = True\n",
    "            sequence = []  # Reset sequence\n",
    "            frames_collected = 0  # Reset frame counter\n",
    "            print(\"Collecting frames...\")\n",
    "        elif key == ord('q'):  # Quit program\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098c69c-9595-432c-93f1-a10b79eb27a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
